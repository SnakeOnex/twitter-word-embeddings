{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ['king is a strong man', \n",
    "          'queen is a wise woman', \n",
    "          'boy is a young man',\n",
    "          'girl is a young woman',\n",
    "          'prince is a young king',\n",
    "          'princess is a young queen',\n",
    "          'man is strong', \n",
    "          'woman is pretty',\n",
    "          'prince is a boy will be king',\n",
    "          'princess is a girl will be queen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(corpus):\n",
    "    stop_words = [\"is\", \"a\", \"will\", \"be\"]\n",
    "    results = []\n",
    "    for text in corpus:\n",
    "        tmp = text.split(' ')\n",
    "        for stop_word in stop_words:\n",
    "            if stop_word in tmp:\n",
    "                tmp.remove(stop_word)\n",
    "        results.append(\" \".join(tmp))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = remove_stop_words(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_set(corpus):\n",
    "    words = []\n",
    "    for line in corpus:\n",
    "        for word in line.split(' '):\n",
    "            words.append(word)\n",
    "    return set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boy',\n",
       " 'girl',\n",
       " 'king',\n",
       " 'man',\n",
       " 'pretty',\n",
       " 'prince',\n",
       " 'princess',\n",
       " 'queen',\n",
       " 'strong',\n",
       " 'wise',\n",
       " 'woman',\n",
       " 'young'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = get_set(corpus)\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skip-gram part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prince': 0,\n",
       " 'girl': 1,\n",
       " 'queen': 2,\n",
       " 'man': 3,\n",
       " 'boy': 4,\n",
       " 'young': 5,\n",
       " 'pretty': 6,\n",
       " 'woman': 7,\n",
       " 'princess': 8,\n",
       " 'strong': 9,\n",
       " 'king': 10,\n",
       " 'wise': 11}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2int = {}\n",
    "for i, word in enumerate(words):\n",
    "    word2int[word] = i\n",
    "word2int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['king', 'strong', 'man'],\n",
       " ['queen', 'wise', 'woman'],\n",
       " ['boy', 'young', 'man'],\n",
       " ['girl', 'young', 'woman'],\n",
       " ['prince', 'young', 'king'],\n",
       " ['princess', 'young', 'queen'],\n",
       " ['man', 'strong'],\n",
       " ['woman', 'pretty'],\n",
       " ['prince', 'boy', 'king'],\n",
       " ['princess', 'girl', 'queen']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = []\n",
    "for sentence in corpus:\n",
    "    sentences.append(sentence.split(' '))\n",
    "    \n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "window_size = 2\n",
    "for sentence in sentences:\n",
    "    for i, target in enumerate(sentence):\n",
    "        for word in sentence[max(0, i-window_size):min(len(sentence), i + window_size)+1]:\n",
    "            if target != word:\n",
    "                data.append([target, word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>king</td>\n",
       "      <td>strong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>king</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>strong</td>\n",
       "      <td>king</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>strong</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>man</td>\n",
       "      <td>king</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>man</td>\n",
       "      <td>strong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>queen</td>\n",
       "      <td>wise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>queen</td>\n",
       "      <td>woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>wise</td>\n",
       "      <td>queen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>wise</td>\n",
       "      <td>woman</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    input   label\n",
       "0    king  strong\n",
       "1    king     man\n",
       "2  strong    king\n",
       "3  strong     man\n",
       "4     man    king\n",
       "5     man  strong\n",
       "6   queen    wise\n",
       "7   queen   woman\n",
       "8    wise   queen\n",
       "9    wise   woman"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data, columns=['input', 'label'])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prince': 0,\n",
       " 'girl': 1,\n",
       " 'queen': 2,\n",
       " 'man': 3,\n",
       " 'boy': 4,\n",
       " 'young': 5,\n",
       " 'pretty': 6,\n",
       " 'woman': 7,\n",
       " 'princess': 8,\n",
       " 'strong': 9,\n",
       " 'king': 10,\n",
       " 'wise': 11}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2Vec(torch.nn.Module):\n",
    "    def __init__(self, ONE_HOT_DIM, EMBEDDING_DIM):\n",
    "        super(Word2Vec, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(ONE_HOT_DIM, EMBEDDING_DIM)\n",
    "        self.linear2 = torch.nn.Linear(EMBEDDING_DIM, ONE_HOT_DIM)\n",
    "        self.softmax = torch.nn.Softmax()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z1 = self.linear1(x)\n",
    "        z2 = self.linear2(z1)\n",
    "        y_pred = self.softmax(z2)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([52, 12])\n",
      "torch.Size([52, 12])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "ONE_HOT_DIM = len(words)\n",
    "\n",
    "# convert numbers to one hot vectors\n",
    "def to_one_hot_encoding(index):\n",
    "    one_hot_encoding = np.zeros(ONE_HOT_DIM)\n",
    "    one_hot_encoding[index] = 1\n",
    "    return one_hot_encoding\n",
    "\n",
    "X = [] # input word\n",
    "Y = [] # target word\n",
    "\n",
    "for x, y in zip(df['input'], df['label']):\n",
    "    X.append(to_one_hot_encoding(word2int[x]))\n",
    "    Y.append(to_one_hot_encoding(word2int[y]))\n",
    "    \n",
    "X_train = np.float32(X)\n",
    "Y_train = np.float32(Y)\n",
    "\n",
    "X_train = torch.from_numpy(X_train)\n",
    "Y_train = torch.from_numpy(Y_train)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "print(X_train[0])\n",
    "print(Y_train[0])\n",
    "\n",
    "EMBEDDING_DIM = 2\n",
    "\n",
    "# model = torch.nn.Sequential(\n",
    "#     torch.nn.Linear(ONE_HOT_DIM, EMBEDDING_DIM),\n",
    "#     torch.nn.Linear(EMBEDDING_DIM, ONE_HOT_DIM),\n",
    "#     torch.nn.Softmax()\n",
    "# )\n",
    "\n",
    "model = Word2Vec(ONE_HOT_DIM, EMBEDDING_DIM)\n",
    "\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "learning_rate = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 48.39484405517578\n",
      "1 48.118446350097656\n",
      "2 47.92127990722656\n",
      "3 47.7667350769043\n",
      "4 47.64070129394531\n",
      "5 47.53601837158203\n",
      "6 47.44791793823242\n",
      "7 47.372676849365234\n",
      "8 47.30727005004883\n",
      "9 47.24929428100586\n",
      "10 47.19692611694336\n",
      "11 47.148826599121094\n",
      "12 47.10403823852539\n",
      "13 47.061885833740234\n",
      "14 47.02190017700195\n",
      "15 46.98372268676758\n",
      "16 46.94709777832031\n",
      "17 46.91181182861328\n",
      "18 46.877685546875\n",
      "19 46.84457015991211\n",
      "20 46.812320709228516\n",
      "21 46.78081130981445\n",
      "22 46.749916076660156\n",
      "23 46.71951675415039\n",
      "24 46.68950271606445\n",
      "25 46.659759521484375\n",
      "26 46.63018035888672\n",
      "27 46.60065841674805\n",
      "28 46.57109069824219\n",
      "29 46.54137420654297\n",
      "30 46.51140594482422\n",
      "31 46.481082916259766\n",
      "32 46.45030975341797\n",
      "33 46.418983459472656\n",
      "34 46.38700866699219\n",
      "35 46.354286193847656\n",
      "36 46.320716857910156\n",
      "37 46.28620529174805\n",
      "38 46.25065612792969\n",
      "39 46.21398162841797\n",
      "40 46.17608642578125\n",
      "41 46.13688659667969\n",
      "42 46.09630584716797\n",
      "43 46.054264068603516\n",
      "44 46.01070785522461\n",
      "45 45.965576171875\n",
      "46 45.91883850097656\n",
      "47 45.8704719543457\n",
      "48 45.82047653198242\n",
      "49 45.76886749267578\n",
      "50 45.715694427490234\n",
      "51 45.661014556884766\n",
      "52 45.60492706298828\n",
      "53 45.547542572021484\n",
      "54 45.488990783691406\n",
      "55 45.42942428588867\n",
      "56 45.3690071105957\n",
      "57 45.307899475097656\n",
      "58 45.246280670166016\n",
      "59 45.18431091308594\n",
      "60 45.122154235839844\n",
      "61 45.05995559692383\n",
      "62 44.997859954833984\n",
      "63 44.93598937988281\n",
      "64 44.87446594238281\n",
      "65 44.81339645385742\n",
      "66 44.75288391113281\n",
      "67 44.693023681640625\n",
      "68 44.6339111328125\n",
      "69 44.57563018798828\n",
      "70 44.51826477050781\n",
      "71 44.461891174316406\n",
      "72 44.40657424926758\n",
      "73 44.352378845214844\n",
      "74 44.299354553222656\n",
      "75 44.247528076171875\n",
      "76 44.196929931640625\n",
      "77 44.147560119628906\n",
      "78 44.09941482543945\n",
      "79 44.05247116088867\n",
      "80 44.00669479370117\n",
      "81 43.962039947509766\n",
      "82 43.91844940185547\n",
      "83 43.87586975097656\n",
      "84 43.834224700927734\n",
      "85 43.7934455871582\n",
      "86 43.75346374511719\n",
      "87 43.71420669555664\n",
      "88 43.675601959228516\n",
      "89 43.6375846862793\n",
      "90 43.60009002685547\n",
      "91 43.563053131103516\n",
      "92 43.52642059326172\n",
      "93 43.490142822265625\n",
      "94 43.45417022705078\n",
      "95 43.418460845947266\n",
      "96 43.38297653198242\n",
      "97 43.34768295288086\n",
      "98 43.31255340576172\n",
      "99 43.27756118774414\n",
      "100 43.24268341064453\n",
      "101 43.20790100097656\n",
      "102 43.1732063293457\n",
      "103 43.138587951660156\n",
      "104 43.10403823852539\n",
      "105 43.06955337524414\n",
      "106 43.035133361816406\n",
      "107 43.00078582763672\n",
      "108 42.966514587402344\n",
      "109 42.93233871459961\n",
      "110 42.89826202392578\n",
      "111 42.86430740356445\n",
      "112 42.83049392700195\n",
      "113 42.79684066772461\n",
      "114 42.76337432861328\n",
      "115 42.73012161254883\n",
      "116 42.697105407714844\n",
      "117 42.66435623168945\n",
      "118 42.63189697265625\n",
      "119 42.599754333496094\n",
      "120 42.56795883178711\n",
      "121 42.536529541015625\n",
      "122 42.5054931640625\n",
      "123 42.4748649597168\n",
      "124 42.444664001464844\n",
      "125 42.41490936279297\n",
      "126 42.3856086730957\n",
      "127 42.35676956176758\n",
      "128 42.328399658203125\n",
      "129 42.300506591796875\n",
      "130 42.27308654785156\n",
      "131 42.24613952636719\n",
      "132 42.21965789794922\n",
      "133 42.19363784790039\n",
      "134 42.16807556152344\n",
      "135 42.14295196533203\n",
      "136 42.118255615234375\n",
      "137 42.0939826965332\n",
      "138 42.070106506347656\n",
      "139 42.0466194152832\n",
      "140 42.023502349853516\n",
      "141 42.0007438659668\n",
      "142 41.97831726074219\n",
      "143 41.95621109008789\n",
      "144 41.93440628051758\n",
      "145 41.91288375854492\n",
      "146 41.891632080078125\n",
      "147 41.87062454223633\n",
      "148 41.849849700927734\n",
      "149 41.82929229736328\n",
      "150 41.80893325805664\n",
      "151 41.788753509521484\n",
      "152 41.768741607666016\n",
      "153 41.74888229370117\n",
      "154 41.72916030883789\n",
      "155 41.70956039428711\n",
      "156 41.6900749206543\n",
      "157 41.67068099975586\n",
      "158 41.65137481689453\n",
      "159 41.632144927978516\n",
      "160 41.612972259521484\n",
      "161 41.59385681152344\n",
      "162 41.57477951049805\n",
      "163 41.55573654174805\n",
      "164 41.53671646118164\n",
      "165 41.5177116394043\n",
      "166 41.498714447021484\n",
      "167 41.47971725463867\n",
      "168 41.46070861816406\n",
      "169 41.441688537597656\n",
      "170 41.422645568847656\n",
      "171 41.40357971191406\n",
      "172 41.38447952270508\n",
      "173 41.36534118652344\n",
      "174 41.346160888671875\n",
      "175 41.32693862915039\n",
      "176 41.30766296386719\n",
      "177 41.288333892822266\n",
      "178 41.26894760131836\n",
      "179 41.24950408935547\n",
      "180 41.22999572753906\n",
      "181 41.210426330566406\n",
      "182 41.190792083740234\n",
      "183 41.17108917236328\n",
      "184 41.15131759643555\n",
      "185 41.1314811706543\n",
      "186 41.111572265625\n",
      "187 41.09160232543945\n",
      "188 41.07155990600586\n",
      "189 41.051456451416016\n",
      "190 41.031288146972656\n",
      "191 41.01106262207031\n",
      "192 40.99077606201172\n",
      "193 40.97043228149414\n",
      "194 40.950042724609375\n",
      "195 40.929603576660156\n",
      "196 40.909122467041016\n",
      "197 40.88860321044922\n",
      "198 40.86805725097656\n",
      "199 40.84748077392578\n",
      "200 40.82688903808594\n",
      "201 40.80628204345703\n",
      "202 40.785675048828125\n",
      "203 40.76506805419922\n",
      "204 40.74447250366211\n",
      "205 40.723899841308594\n",
      "206 40.70335388183594\n",
      "207 40.68284606933594\n",
      "208 40.66238784790039\n",
      "209 40.64198684692383\n",
      "210 40.62165451049805\n",
      "211 40.60139846801758\n",
      "212 40.58123779296875\n",
      "213 40.56117630004883\n",
      "214 40.541229248046875\n",
      "215 40.52140808105469\n",
      "216 40.5017204284668\n",
      "217 40.48218536376953\n",
      "218 40.46281051635742\n",
      "219 40.44361114501953\n",
      "220 40.424598693847656\n",
      "221 40.40578079223633\n",
      "222 40.38717269897461\n",
      "223 40.36878204345703\n",
      "224 40.35062026977539\n",
      "225 40.332698822021484\n",
      "226 40.315025329589844\n",
      "227 40.297607421875\n",
      "228 40.280452728271484\n",
      "229 40.26356506347656\n",
      "230 40.2469482421875\n",
      "231 40.23060607910156\n",
      "232 40.21454620361328\n",
      "233 40.19876480102539\n",
      "234 40.183265686035156\n",
      "235 40.16804122924805\n",
      "236 40.153099060058594\n",
      "237 40.138431549072266\n",
      "238 40.1240348815918\n",
      "239 40.10990524291992\n",
      "240 40.096038818359375\n",
      "241 40.082427978515625\n",
      "242 40.069068908691406\n",
      "243 40.05595779418945\n",
      "244 40.04308319091797\n",
      "245 40.03044128417969\n",
      "246 40.01802444458008\n",
      "247 40.005828857421875\n",
      "248 39.993839263916016\n",
      "249 39.982059478759766\n",
      "250 39.97047424316406\n",
      "251 39.959075927734375\n",
      "252 39.9478645324707\n",
      "253 39.936832427978516\n",
      "254 39.925968170166016\n",
      "255 39.91526794433594\n",
      "256 39.904727935791016\n",
      "257 39.89434051513672\n",
      "258 39.884098052978516\n",
      "259 39.874000549316406\n",
      "260 39.864036560058594\n",
      "261 39.85420227050781\n",
      "262 39.8444938659668\n",
      "263 39.83490753173828\n",
      "264 39.825439453125\n",
      "265 39.81608200073242\n",
      "266 39.80683135986328\n",
      "267 39.79768371582031\n",
      "268 39.788639068603516\n",
      "269 39.77968978881836\n",
      "270 39.770835876464844\n",
      "271 39.76206970214844\n",
      "272 39.75339126586914\n",
      "273 39.74479293823242\n",
      "274 39.73627853393555\n",
      "275 39.727840423583984\n",
      "276 39.71947479248047\n",
      "277 39.71118927001953\n",
      "278 39.70296859741211\n",
      "279 39.694820404052734\n",
      "280 39.686737060546875\n",
      "281 39.6787223815918\n",
      "282 39.67076873779297\n",
      "283 39.662879943847656\n",
      "284 39.65505599975586\n",
      "285 39.64728927612305\n",
      "286 39.63958740234375\n",
      "287 39.63194274902344\n",
      "288 39.624359130859375\n",
      "289 39.61683654785156\n",
      "290 39.609375\n",
      "291 39.60197067260742\n",
      "292 39.59463119506836\n",
      "293 39.58735656738281\n",
      "294 39.580142974853516\n",
      "295 39.572994232177734\n",
      "296 39.565914154052734\n",
      "297 39.55889892578125\n",
      "298 39.55195617675781\n",
      "299 39.545082092285156\n",
      "300 39.53828048706055\n",
      "301 39.53155517578125\n",
      "302 39.524906158447266\n",
      "303 39.51833724975586\n",
      "304 39.5118522644043\n",
      "305 39.50544738769531\n",
      "306 39.49912643432617\n",
      "307 39.49289321899414\n",
      "308 39.48674774169922\n",
      "309 39.480690002441406\n",
      "310 39.474727630615234\n",
      "311 39.46885681152344\n",
      "312 39.463077545166016\n",
      "313 39.457393646240234\n",
      "314 39.451805114746094\n",
      "315 39.446311950683594\n",
      "316 39.44091033935547\n",
      "317 39.43560791015625\n",
      "318 39.430397033691406\n",
      "319 39.4252815246582\n",
      "320 39.42026138305664\n",
      "321 39.41532897949219\n",
      "322 39.410491943359375\n",
      "323 39.405738830566406\n",
      "324 39.40107727050781\n",
      "325 39.39650344848633\n",
      "326 39.39200973510742\n",
      "327 39.38759994506836\n",
      "328 39.383270263671875\n",
      "329 39.37902069091797\n",
      "330 39.374847412109375\n",
      "331 39.37074661254883\n",
      "332 39.36671829223633\n",
      "333 39.362762451171875\n",
      "334 39.3588752746582\n",
      "335 39.35504913330078\n",
      "336 39.35129165649414\n",
      "337 39.34759521484375\n",
      "338 39.343955993652344\n",
      "339 39.34038162231445\n",
      "340 39.336856842041016\n",
      "341 39.33339309692383\n",
      "342 39.329978942871094\n",
      "343 39.32661437988281\n",
      "344 39.32330322265625\n",
      "345 39.32004165649414\n",
      "346 39.31682205200195\n",
      "347 39.31365203857422\n",
      "348 39.31052780151367\n",
      "349 39.30744552612305\n",
      "350 39.30440139770508\n",
      "351 39.3014030456543\n",
      "352 39.29844284057617\n",
      "353 39.2955207824707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/snakeone/anaconda3/envs/pytorch/lib/python3.7/site-packages/ipykernel_launcher.py:11: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354 39.292633056640625\n",
      "355 39.28978729248047\n",
      "356 39.28697204589844\n",
      "357 39.28419494628906\n",
      "358 39.28145217895508\n",
      "359 39.27873992919922\n",
      "360 39.27606201171875\n",
      "361 39.273414611816406\n",
      "362 39.27079772949219\n",
      "363 39.268211364746094\n",
      "364 39.265655517578125\n",
      "365 39.263126373291016\n",
      "366 39.26062774658203\n",
      "367 39.25815200805664\n",
      "368 39.255706787109375\n",
      "369 39.25328826904297\n",
      "370 39.250892639160156\n",
      "371 39.2485237121582\n",
      "372 39.24618148803711\n",
      "373 39.24386215209961\n",
      "374 39.2415657043457\n",
      "375 39.23929214477539\n",
      "376 39.23704147338867\n",
      "377 39.23481750488281\n",
      "378 39.232608795166016\n",
      "379 39.23042678833008\n",
      "380 39.22826385498047\n",
      "381 39.22612380981445\n",
      "382 39.224002838134766\n",
      "383 39.221900939941406\n",
      "384 39.219818115234375\n",
      "385 39.21775817871094\n",
      "386 39.21571350097656\n",
      "387 39.21369171142578\n",
      "388 39.21168518066406\n",
      "389 39.20969772338867\n",
      "390 39.20772933959961\n",
      "391 39.205780029296875\n",
      "392 39.2038459777832\n",
      "393 39.201927185058594\n",
      "394 39.20002746582031\n",
      "395 39.198143005371094\n",
      "396 39.1962776184082\n",
      "397 39.19442367553711\n",
      "398 39.19259262084961\n",
      "399 39.190773010253906\n",
      "400 39.18896484375\n",
      "401 39.18717575073242\n",
      "402 39.185401916503906\n",
      "403 39.18364334106445\n",
      "404 39.18190002441406\n",
      "405 39.18016815185547\n",
      "406 39.17845153808594\n",
      "407 39.17675018310547\n",
      "408 39.1750602722168\n",
      "409 39.17338562011719\n",
      "410 39.171722412109375\n",
      "411 39.170074462890625\n",
      "412 39.16843795776367\n",
      "413 39.16681671142578\n",
      "414 39.16520690917969\n",
      "415 39.16360855102539\n",
      "416 39.16202163696289\n",
      "417 39.16044998168945\n",
      "418 39.15888977050781\n",
      "419 39.1573371887207\n",
      "420 39.155799865722656\n",
      "421 39.154273986816406\n",
      "422 39.15275955200195\n",
      "423 39.1512565612793\n",
      "424 39.14976501464844\n",
      "425 39.148284912109375\n",
      "426 39.146812438964844\n",
      "427 39.14535140991211\n",
      "428 39.14390563964844\n",
      "429 39.14246368408203\n",
      "430 39.14103698730469\n",
      "431 39.139617919921875\n",
      "432 39.13821029663086\n",
      "433 39.13681411743164\n",
      "434 39.13542556762695\n",
      "435 39.1340446472168\n",
      "436 39.13267517089844\n",
      "437 39.131317138671875\n",
      "438 39.129966735839844\n",
      "439 39.128623962402344\n",
      "440 39.12729263305664\n",
      "441 39.12596893310547\n",
      "442 39.124656677246094\n",
      "443 39.12335205078125\n",
      "444 39.12205505371094\n",
      "445 39.120765686035156\n",
      "446 39.11948776245117\n",
      "447 39.11821746826172\n",
      "448 39.1169548034668\n",
      "449 39.115699768066406\n",
      "450 39.11445236206055\n",
      "451 39.113216400146484\n",
      "452 39.11198425292969\n",
      "453 39.11076354980469\n",
      "454 39.10954666137695\n",
      "455 39.108341217041016\n",
      "456 39.107139587402344\n",
      "457 39.1059455871582\n",
      "458 39.10476303100586\n",
      "459 39.10358428955078\n",
      "460 39.102413177490234\n",
      "461 39.10124969482422\n",
      "462 39.100093841552734\n",
      "463 39.09894561767578\n",
      "464 39.097801208496094\n",
      "465 39.09666442871094\n",
      "466 39.09553527832031\n",
      "467 39.09441375732422\n",
      "468 39.093299865722656\n",
      "469 39.09218978881836\n",
      "470 39.091087341308594\n",
      "471 39.089988708496094\n",
      "472 39.08890151977539\n",
      "473 39.08781433105469\n",
      "474 39.08673858642578\n",
      "475 39.08566665649414\n",
      "476 39.084598541259766\n",
      "477 39.08354187011719\n",
      "478 39.08248519897461\n",
      "479 39.08143615722656\n",
      "480 39.08039474487305\n",
      "481 39.0793571472168\n",
      "482 39.07832717895508\n",
      "483 39.077301025390625\n",
      "484 39.0762825012207\n",
      "485 39.07526397705078\n",
      "486 39.074256896972656\n",
      "487 39.0732536315918\n",
      "488 39.0722541809082\n",
      "489 39.071258544921875\n",
      "490 39.07027053833008\n",
      "491 39.06928634643555\n",
      "492 39.06830978393555\n",
      "493 39.06733322143555\n",
      "494 39.066368103027344\n",
      "495 39.06540298461914\n",
      "496 39.06444549560547\n",
      "497 39.06349182128906\n",
      "498 39.06254196166992\n",
      "499 39.06159591674805\n"
     ]
    }
   ],
   "source": [
    "for t in range(500):\n",
    "    \n",
    "    y_pred = model(X_train)\n",
    "    loss = loss_fn(y_pred, Y_train)\n",
    "    print(t, loss.item())\n",
    "    \n",
    "    model.zero_grad()\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for param in model.parameters():\n",
    "            param -= learning_rate * param.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 12])\n"
     ]
    }
   ],
   "source": [
    "print(model.linear1.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.022875   -0.8754933  -0.11785867  0.21894585  1.100892    0.53299946\n",
      "  -1.715776   -0.6139958  -1.2047893   3.0685062   0.9126718  -2.7486134 ]\n",
      " [-1.2745206   0.33084053  0.5941604  -2.7677171   0.33171302  0.6297283\n",
      "   2.1866744  -0.3355597  -0.9603005  -0.43434876  0.68866915  0.44242463]]\n"
     ]
    }
   ],
   "source": [
    "print(model.linear1.weight.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
